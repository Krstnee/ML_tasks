{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKMq7dp2W15Y"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWCBWxrBUB3"
      },
      "source": [
        "## 1. Генерирование русских имен при помощи RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2XA3ioBVLfY",
        "outputId": "02ded3b8-88ef-49db-f975-2a1f045ac644"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>авдокея</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>авдоким</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      name\n",
              "0  авдокея\n",
              "1  авдоким"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "names = pd.read_csv(\"./data/name_rus.txt\",\n",
        "            encoding=\"cp1251\", header=None, names=[\"name\"])\n",
        "names.name = names.name.str.lower().str.strip()\n",
        "names.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eixmimwKVLfZ"
      },
      "source": [
        "Датасет: https://disk.yandex.ru/i/2yt18jHUgVEoIw\n",
        "\n",
        "1.1 На основе файла name_rus.txt создайте датасет.\n",
        "  * Учтите, что имена могут иметь различную длину\n",
        "  * Добавьте 4 специальных токена:\n",
        "    * `<PAD>` для дополнения последовательности до нужной длины;\n",
        "    * `<UNK>` для корректной обработки ранее не встречавшихся токенов;\n",
        "    * `<SOS>` для обозначения начала последовательности;\n",
        "    * `<EOS>` для обозначения конца последовательности.\n",
        "  * Преобразовывайте строку в последовательность индексов с учетом следующих замечаний:\n",
        "    * в начало последовательности добавьте токен `<SOS>`;\n",
        "    * в конец последовательности добавьте токен `<EOS>` и, при необходимости, несколько токенов `<PAD>`;\n",
        "  * `Dataset.__get_item__` возращает две последовательности: последовательность для обучения и правильный ответ.\n",
        "  \n",
        "  Пример:\n",
        "  ```\n",
        "  s = 'The cat sat on the mat'\n",
        "  # преобразуем в индексы\n",
        "  s_idx = [2, 5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
        "  # получаем x и y (__getitem__)\n",
        "  x = [2, 5, 1, 2, 8, 4, 7, 3, 0]\n",
        "  y = [5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15iqa7c-VLfa"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, names):\n",
        "        xs = names.iloc[:, 0]\n",
        "        self.max_seq_len = xs.str.len().max()\n",
        "        tokens = set()\n",
        "        for name in xs:\n",
        "            tokens.update(name)\n",
        "        self.idx_to_token = dict(enumerate(tokens, 4))\n",
        "        self.idx_to_token[0] = \"<PAD>\"\n",
        "        self.idx_to_token[1] = \"<UNK>\"\n",
        "        self.idx_to_token[2] = \"<SOS>\"\n",
        "        self.idx_to_token[3] = \"<EOS>\"\n",
        "        self.token_to_idx = {token: idx for idx, token in self.idx_to_token.items()}\n",
        "        self.vocab_len = len(self.idx_to_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5RIBuTJVLfa"
      },
      "outputs": [],
      "source": [
        "class RusNamesDataset(Dataset):\n",
        "    def __init__(self, X, vocab: Vocab):\n",
        "        self.X = X\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def vectorize(self, surname):\n",
        "        surname = surname[:vocab.max_seq_len]\n",
        "        surname_t = torch.zeros(self.vocab.max_seq_len+2).type(torch.long)\n",
        "        surname_t += self.vocab.token_to_idx[\"<PAD>\"]\n",
        "        for i, token in enumerate(surname, 1):\n",
        "            try:\n",
        "                surname_t[i] = self.vocab.token_to_idx[token]\n",
        "            except IndexError as e:\n",
        "                surname_t[i] = self.vocab.token_to_idx[\"<UNK>\"]\n",
        "        surname_t[0] = self.vocab.token_to_idx[\"<SOS>\"]\n",
        "        surname_t[-1] = self.vocab.token_to_idx[\"<EOS>\"]\n",
        "        return surname_t[:-1], surname_t[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.vectorize(self.X[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVK29aWAVLfb"
      },
      "outputs": [],
      "source": [
        "vocab = Vocab(names)\n",
        "dataset = RusNamesDataset(names.name.values, vocab)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4rlWnOGVLfc"
      },
      "source": [
        "1.2 Создайте и обучите модель для генерации фамилии.\n",
        "\n",
        "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`;\n",
        "  * Используйте рекуррентные слои;\n",
        "  * Задача ставится как предсказание следующего токена в каждом примере из пакета для каждого момента времени. Т.е. в данный момент времени по текущей подстроке предсказывает следующий символ для данной строки (задача классификации);\n",
        "  * Примерная схема реализации метода `forward`:\n",
        "  ```\n",
        "    input_X: [batch_size x seq_len] -> nn.Embedding -> emb_X: [batch_size x seq_len x embedding_size]\n",
        "    emb_X: [batch_size x seq_len x embedding_size] -> nn.RNN -> output: [batch_size x seq_len x hidden_size]\n",
        "    output: [batch_size x seq_len x hidden_size] -> torch.Tensor.reshape -> output: [batch_size * seq_len x hidden_size]\n",
        "    output: [batch_size * seq_len x hidden_size] -> nn.Linear -> output: [batch_size * seq_len x vocab_size]\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSYDyKcpVLfd"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, vocab_len, embedding_dim, hidden_size, padding_idx,\n",
        "                 num_layers=1):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(padding_idx=padding_idx,\n",
        "            num_embeddings=vocab_len, embedding_dim=embedding_dim)\n",
        "        self.rnn = nn.RNN(num_layers=num_layers, batch_first=True,\n",
        "            input_size=embedding_dim, hidden_size=hidden_size)\n",
        "        self.fc = nn.Linear(in_features=hidden_size, out_features=vocab_len)\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "        x, h = self.rnn(x, h)\n",
        "        x = self.fc(x)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd8_cnK7VLfe"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_len=vocab.vocab_len,\n",
        "    embedding_dim=32,\n",
        "    hidden_size=64,\n",
        "    padding_idx=vocab.token_to_idx[\"<PAD>\"],\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "NT5FgSI5YQqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyhNWWqEVLfe",
        "outputId": "36524097-fe56-43fa-8931-88ab3a6ea47d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# 0 --- loss [1.5506]\n",
            "#10 --- loss [0.9683]\n",
            "#20 --- loss [0.8864]\n",
            "#30 --- loss [0.8391]\n",
            "#40 --- loss [0.8010]\n",
            "#50 --- loss [0.7751]\n",
            "#60 --- loss [0.7506]\n",
            "#70 --- loss [0.7347]\n",
            "#80 --- loss [0.7202]\n",
            "#90 --- loss [0.7059]\n",
            "#100 --- loss [0.6986]\n"
          ]
        }
      ],
      "source": [
        "epoch_step = 10\n",
        "n_epochs = 101\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = torch.empty(0)\n",
        "    y_true = torch.empty(0, dtype=torch.long)\n",
        "    model.train()\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions, h = model(X_batch)\n",
        "        loss = criterion(predictions.transpose(1, -1), y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y_true = torch.cat((y_true, y_batch))\n",
        "            y_pred = torch.cat((y_pred, predictions))\n",
        "    with torch.no_grad():\n",
        "        train_loss = criterion(y_pred.transpose(1, -1), y_true).item()\n",
        "    if epoch % epoch_step == 0:\n",
        "        print(f\"#{epoch:3d} --- loss [{train_loss:.4f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "990obDBwCC7V"
      },
      "source": [
        "1.3 Напишите функцию, которая генерирует фамилию при помощи обученной модели:\n",
        "  * Построение начинается с последовательности единичной длины, состоящей из индекса токена `<SOS>`;\n",
        "  * Начальное скрытое состояние RNN `h_t = None`;\n",
        "  * В результате прогона последнего токена из построенной последовательности через модель получаете новое скрытое состояние `h_t` и распределение над всеми токенами из словаря;\n",
        "  * Выбираете 1 токен пропорционально вероятности и добавляете его в последовательность (можно воспользоваться `torch.multinomial`);\n",
        "  * Повторяете эти действия до тех пор, пока не сгенерирован токен `<EOS>` или не превышена максимальная длина последовательности.\n",
        "\n",
        "При обучении каждые `k` эпох генерируйте несколько фамилий и выводите их на экран."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOWP1traVLff"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, vocab, embedding_dim, hidden_size, num_layers=1):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(padding_idx=vocab.token_to_idx[\"<PAD>\"],\n",
        "            num_embeddings=vocab.vocab_len, embedding_dim=embedding_dim)\n",
        "        self.rnn = nn.RNN(num_layers=num_layers, batch_first=True,\n",
        "            input_size=embedding_dim, hidden_size=hidden_size)\n",
        "        self.fc = nn.Linear(\n",
        "            in_features=hidden_size, out_features=vocab.vocab_len)\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "        x, h = self.rnn(x, h)\n",
        "        x = self.fc(x)\n",
        "        return x, h\n",
        "\n",
        "    def random_word(self):\n",
        "        h = None\n",
        "        word = []\n",
        "        token = torch.tensor([[vocab.token_to_idx[\"<SOS>\"]]])\n",
        "        for _ in range(self.vocab.max_seq_len):\n",
        "            out, h = self(token, h)\n",
        "            out_random = out.squeeze().softmax(-1).multinomial(1)\n",
        "            letter = self.vocab.idx_to_token[out_random.item()]\n",
        "            if letter == \"<EOS>\":\n",
        "                break\n",
        "            word.append(letter)\n",
        "            token = out_random.view(1, 1)\n",
        "        clear = [letter for letter in word if letter not in [\n",
        "            \"<PAD>\",\"<EOS>\",\"<SOS>\",\"<UNK>\"]]\n",
        "        generated = \"\".join(word).capitalize()\n",
        "        clear = \"\".join(clear).capitalize()\n",
        "        return generated, clear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4d9wFZZVLff"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab=vocab,\n",
        "    embedding_dim=32,\n",
        "    hidden_size=64,\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuIl1aRzVLfg",
        "outputId": "86828190-7afa-4aa0-be9a-7f150e29343e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#  0 --- loss [2.2938]\n",
            "Алтнфб, Алреная, Лиднун, Дфиошиа, Пфрорю, Внйдета, Лчкеваналд, Асдиу, Виафатх, Вмиеаыаа\n",
            "# 10 --- loss [0.9925]\n",
            "Фэлюха, Алонтейын, Евося, Линя, Митуша, Ювяй, Инксилья, Трскавр, Веля, Едоша\n",
            "# 20 --- loss [0.9093]\n",
            "Корьай, Видора, Гарий, Леяра, Леманьич, Коля, Пегая, Падуня, Селья, Парося\n",
            "# 30 --- loss [0.8589]\n",
            "Вермюша, Тома, Валюша, Гетуся, Веля, Темалин, Кольона, Верктушя, Гельюшка, Настадка\n",
            "# 40 --- loss [0.8169]\n",
            "Иросеша, Нюхаиктай, Доря, Петюра, Апа, Мулиан, Ваислешка, Леда, Варюня, Гася\n",
            "# 50 --- loss [0.7931]\n",
            "Кита, Кирина, Никуля, Вируха, Паврюша, Филюша, Бероша, Варсич, Римуся, Бенюня\n",
            "# 60 --- loss [0.7668]\n",
            "Еждя, Диктуша, Нисент, Елюша, Юратюта, Мальб, Нюта, Панюшка, Владиска, Артонина\n",
            "# 70 --- loss [0.7522]\n",
            "Маруха, Павра, Алене, Нидилианка, Емилинка, Ситефмианка, Анатима, Лодя, Лаврена, Тюта\n",
            "# 80 --- loss [0.7333]\n",
            "Васяна, Ирася, Авдоня, Миняша, Петря, Лизанель, Васяша, Дуся, Маналя, Петря\n",
            "# 90 --- loss [0.7196]\n",
            "Антоныч, Коля, Докитка, Дониска, Катанодыч, Максин, Лежаша, Филия, Емаша, Кутуся\n",
            "#100 --- loss [0.7083]\n",
            "Вася, Эллуня, Илуша, Волюха, Алидуся, Дарья, Павлуня, Павилий, Нилка, Марианка\n"
          ]
        }
      ],
      "source": [
        "epoch_step = 10\n",
        "n_epochs = 101\n",
        "n_words = 10\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = torch.empty(0)\n",
        "    y_true = torch.empty(0, dtype=torch.long)\n",
        "    model.train()\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions, h = model(X_batch)\n",
        "        loss = criterion(predictions.transpose(1, -1), y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y_true = torch.cat((y_true, y_batch))\n",
        "            y_pred = torch.cat((y_pred, predictions))\n",
        "    with torch.no_grad():\n",
        "        train_loss = criterion(y_pred.transpose(1, -1), y_true).item()\n",
        "    if epoch % epoch_step == 0:\n",
        "        print(f\"#{epoch:3d} --- loss [{train_loss:.4f}]\")\n",
        "        words=[]\n",
        "        for _ in range(n_words):\n",
        "            _, clear = model.random_word()\n",
        "            words.append(clear)\n",
        "        print(\", \".join(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJf5iaA2fOTM"
      },
      "source": [
        "## 2. Генерирование текста при помощи RNN\n",
        "\n",
        "2.1 Скачайте из интернета какое-нибудь художественное произведение\n",
        "  * Выбирайте достаточно крупное произведение, чтобы модель лучше обучалась;\n",
        "\n",
        "2.2 На основе выбранного произведения создайте датасет.\n",
        "\n",
        "Отличия от задачи 1:\n",
        "  * Токены <SOS>, `<EOS>` и `<UNK>` можно не добавлять;\n",
        "  * При создании датасета текст необходимо предварительно разбить на части. Выберите желаемую длину последовательности `seq_len` и разбейте текст на построки длины `seq_len` (можно без перекрытия, можно с небольшим перекрытием)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTh4xBi0VLfg"
      },
      "outputs": [],
      "source": [
        "text = \"\"\n",
        "for i in range(1, 5):\n",
        "    with open(f\"./data/wap{i}.txt\", 'r', encoding='ansi') as f:\n",
        "        text += f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrH-nN_9VLfh"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, text):\n",
        "        tokens = set(text)\n",
        "        self.idx_to_token = dict(enumerate(tokens, 2))\n",
        "        self.idx_to_token[0] = \"<PAD>\"\n",
        "        self.idx_to_token[1] = \"<SOS>\"\n",
        "        self.token_to_idx = {token: idx for idx, token in self.idx_to_token.items()}\n",
        "        self.vocab_len = len(self.idx_to_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAz_ymuyVLfh"
      },
      "outputs": [],
      "source": [
        "class BookDataset(Dataset):\n",
        "    def __init__(self, text, vocab: Vocab, seq_len=128, shift=None):\n",
        "        self.seq_len = seq_len\n",
        "        self.shift = shift\n",
        "        self.X = self.__text_split(text)\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __text_split(self, text):\n",
        "        if self.shift is None:\n",
        "            self.shift = self.seq_len // 4\n",
        "        start = 0\n",
        "        X = []\n",
        "        while start < len(text):\n",
        "            X.append(text[start:start+self.seq_len])\n",
        "            start += self.shift\n",
        "        return np.array(X)\n",
        "\n",
        "    def vectorize(self, fragment):\n",
        "        fragment_t = torch.zeros(self.seq_len+1).long()\n",
        "        fragment_t += self.vocab.token_to_idx[\"<PAD>\"]\n",
        "        for i, token in enumerate(fragment, 1):\n",
        "            fragment_t[i] = self.vocab.token_to_idx[token]\n",
        "        fragment_t[0] = self.vocab.token_to_idx[\"<SOS>\"]\n",
        "        return fragment_t[:-1], fragment_t[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.vectorize(self.X[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ie4QKUcVLfh"
      },
      "outputs": [],
      "source": [
        "vocab = Vocab(text)\n",
        "dataset = BookDataset(text, vocab)\n",
        "dataloader = DataLoader(dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cdf6E95VLfh"
      },
      "source": [
        "2.3 Создайте и обучите модель для генерации текста\n",
        "  * Задача ставится точно так же как в 1.2;\n",
        "  * При необходимости можете применить:\n",
        "    * двухуровневые рекуррентные слои (`num_layers`=2)\n",
        "    * [обрезку градиентов](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "\n",
        "2.4 Напишите функцию, которая генерирует фрагмент текста при помощи обученной модели\n",
        "  * Процесс генерации начинается с небольшого фрагмента текста `prime`, выбранного вами (1-2 слова)\n",
        "  * Сначала вы пропускаете через модель токены из `prime` и генерируете на их основе скрытое состояние рекуррентного слоя `h_t`;\n",
        "  * После этого вы генерируете строку нужной длины аналогично 1.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssyaoedxVLfh"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, vocab, embedding_dim, hidden_size, num_layers=1):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(padding_idx=vocab.token_to_idx[\"<PAD>\"],\n",
        "            num_embeddings=vocab.vocab_len, embedding_dim=embedding_dim)\n",
        "        self.rnn = nn.LSTM(num_layers=num_layers, batch_first=True,\n",
        "            input_size=embedding_dim, hidden_size=hidden_size)\n",
        "        self.fc = nn.Linear(\n",
        "            in_features=hidden_size, out_features=vocab.vocab_len)\n",
        "\n",
        "    def forward(self, x, hc=None):\n",
        "        x = self.embedding(x)\n",
        "        x, hc = self.rnn(x, hc)\n",
        "        x = self.fc(x)\n",
        "        return x, hc\n",
        "\n",
        "    def gen_fragment(self, length=256):\n",
        "        hc = None\n",
        "        word = []\n",
        "        token = torch.tensor([[vocab.token_to_idx[\"<SOS>\"]]])\n",
        "        for _ in range(length):\n",
        "            out, hc = self(token, hc)\n",
        "            out_random = out.squeeze().softmax(-1).multinomial(1)\n",
        "            letter = self.vocab.idx_to_token[out_random.item()]\n",
        "            word.append(letter)\n",
        "            token = out_random.view(1, 1)\n",
        "        clear = [letter for letter in word if letter not in [\n",
        "            \"<PAD>\",\"<EOS>\",\"<SOS>\",\"<UNK>\"]]\n",
        "        generated = \"\".join(word).capitalize()\n",
        "        clear = \"\".join(clear).capitalize()\n",
        "        return generated, clear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXNEUozWVLfh"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab=vocab,\n",
        "    embedding_dim=32,\n",
        "    hidden_size=64,\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KH2EeXd9VLfi",
        "outputId": "ef0a2df3-0614-4d27-e28b-7dd2e9b6ef62"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[309], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     15\u001b[0m         y_true \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((y_true, y_batch))\n\u001b[1;32m---> 16\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     18\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m criterion(y_pred\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), y_true)\u001b[38;5;241m.\u001b[39mitem()\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epoch_step = 1\n",
        "n_epochs = 5\n",
        "n_words = 10\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = torch.empty(0)\n",
        "    y_true = torch.empty(0, dtype=torch.long)\n",
        "    model.train()\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions, h = model(X_batch)\n",
        "        loss = criterion(predictions.transpose(1, -1), y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y_true = torch.cat((y_true, y_batch))\n",
        "            y_pred = torch.cat((y_pred, predictions))\n",
        "    with torch.no_grad():\n",
        "        train_loss = criterion(y_pred.transpose(1, -1), y_true).item()\n",
        "    if epoch % epoch_step == 0:\n",
        "        print(f\"#{epoch:3d} --- loss [{train_loss:.4f}]\")\n",
        "        _, clear = model.gen_fragment()\n",
        "        print(\", \".join(clear))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb1XiKtWVLfi",
        "outputId": "d21a56a5-9696-4d33-ecef-f24c7989bdc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "В начале 1806 года Николай Ростов вернулся в отпуск. Денисов ехал тоже домой в Воронеж, и Ростов уговорил его ехать с собой до Москвы и остановиться у них в доме. На предпоследней станции, встретив товарища, Денисов выпил с ним три бутылки вина и подъезжая к Москве, несмотря на ухабы дороги, не просыпался, лежа на дне перекладных саней, подле Ростова, который, по мере приближения к Москве, приходил все более и более в нетерпение.\n"
          ]
        }
      ],
      "source": [
        "gggshechka = \"В начале 1806 года Николай Ростов вернулся в отпуск. Денисов ехал тоже домой в Воронеж, и Ростов уговорил его ехать с собой до Москвы и остановиться у них в доме. На предпоследней станции, встретив товарища, Денисов выпил с ним три бутылки вина и подъезжая к Москве, несмотря на ухабы дороги, не просыпался, лежа на дне перекладных саней, подле Ростова, который, по мере приближения к Москве, приходил все более и более в нетерпение.\"\n",
        "print(gggshechka)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPkpGkc0VLfi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}